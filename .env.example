# Application
APP_NAME=Distributed LLM Serving
APP_VERSION=0.1.0

# Server
HOST=0.0.0.0
PORT=8000
WORKERS=1

# Engine
ENGINE_TYPE=simple
MODEL_NAME=gpt2
MAX_TOKENS=512
TEMPERATURE=0.7

# Performance
MAX_CONCURRENT_REQUESTS=10
REQUEST_TIMEOUT=30

# Backpressure (Milestone 3)
ENABLE_BACKPRESSURE=false
QUEUE_CAPACITY=100

# Observability
ENABLE_METRICS=true
ENABLE_TRACING=true
METRICS_PORT=9090